{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1261f23",
   "metadata": {},
   "source": [
    "# Locate possible outliers in Heave, North, and West data in .RDT files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e01be3f",
   "metadata": {},
   "source": [
    "### Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aec9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of packages (and their functions) used in the modules below\n",
    "using DataFrames: DataFrame, ncol, nrow\n",
    "using Dates: Day, Dates, DateTime, Hour, Microsecond, Minute, Month, Time, unix2datetime, Year\n",
    "using Flux: Adam, Chain, Dense, Flux, mse, params, relu, train!\n",
    "using JLD2\n",
    "using NativeFileDialog: pick_file\n",
    "using Plots:  annotate!, font, hline!, hspan!, plot, Plots, plotly, plot!, scatter!, text, vline!, xlims, ylims, @layout\n",
    "using Printf: @sprintf\n",
    "using Sockets: gethostname\n",
    "using Statistics: mean, median, quantile, std\n",
    "\n",
    "include(\".\\\\Mk3_model_functions.jl\");    # this contains the functions called by the modules below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae1cad-0139-439d-b48d-3249ad052f66",
   "metadata": {},
   "source": [
    "### Locate and display records with GPS errors as flagged by Datawell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9ef10-eae3-4c13-8be9-62f10dbbc1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using DataFrames: DataFrame\n",
    "using Dates: DateTime, year\n",
    "using DSP: welch_pgram, freq, power, hanning\n",
    "using Glob: glob\n",
    "using NativeFileDialog: pick_file\n",
    "\n",
    "import DataFrames: Not, select!\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(HTML(\"<style>.jp-Cell { width: 120% !important; }</style>\"))\n",
    "\n",
    "# Helper function to convert data without creating temporary strings\n",
    "function parse_hex(data_array, idx)\n",
    "###################################\n",
    "    \n",
    "    UInt16(data_array[idx]) << 8 | UInt16(data_array[idx+1])\n",
    "    \n",
    "end    # parse_hex()\n",
    "\n",
    "\n",
    "# Function to check if the LSB is 1 (GPS interference)\n",
    "function check_gps_flag(north_row)\n",
    "##################################\n",
    "    \n",
    "    gps_flag_row = [((n & 0x1) == 1) ? 1 : 0 for n in north_row]\n",
    "    \n",
    "    return(gps_flag_row)\n",
    "    \n",
    "end    # check_gps_flag()\n",
    "    \n",
    "\n",
    "using Plots: plot!, vline\n",
    "using Dates: Microsecond, Minute\n",
    "\n",
    "# plot the selected displacement and GPS errors\n",
    "function plot_pp(xvals, errors, color, X_data, ii, num, tm_tick, ticks)\n",
    "#######################################################################\n",
    "    \n",
    "    pp = vline(xvals[errors], label=\"\", lc=:red, ls=:dot, ylims=extrema(X_data[:,ii,num]) .* 1.1)\n",
    "    pp = plot!(xvals, X_data[:,ii,num], lc=color, label=\"\", xlims=(xvals[1], xvals[end]), xticks=(tm_tick, ticks))\n",
    "\n",
    "    return(pp)\n",
    "\n",
    "end    # plot_pp()\n",
    "    \n",
    "\n",
    "# plot heave, north, and west displacements for selected date\n",
    "function do_plots(ii, X_date, X_data, GPS_errors)\n",
    "#################################################\n",
    "    \n",
    "    start_time = X_date[ii]\n",
    "    errors = findall(x -> x == 1, GPS_errors[:, ii, 1])\n",
    "\n",
    "    xvals = start_time + Microsecond.((0:REC_LENGTH-1) / SAMPLE_FREQUENCY * 1000000)\n",
    "\n",
    "    tm_tick = range(xvals[1], xvals[end], step=Minute(1))\n",
    "    ticks = Dates.format.(tm_tick, \"MM\")\n",
    "\n",
    "    title = Dates.format(X_date[ii], \"yyyy-mm-dd HH:MM\") * \" \" * string(length(errors)) * \" GPS errors\"\n",
    "\n",
    "    p1 = plot_pp(xvals, errors, :blue, X_data, ii, 1, tm_tick, ticks)\n",
    "    p2 = plot_pp(xvals, errors, :red, X_data, ii, 2, tm_tick, ticks)\n",
    "    p3 = plot_pp(xvals, errors, :green, X_data, ii, 3, tm_tick, ticks)\n",
    "    \n",
    "    plot_p1_p2_p3 = plot(p1, p2, p3, size=(2000, 1000), layout=(3,1), dpi=100, framestyle=:box, fg_legend=:transparent, bg_legend=:transparent, \n",
    "        legend=:topright, xtickfont=font(8), ytickfont=font(8), bottommargin=5Plots.mm, suptitle=title, \n",
    "        yformatter = y -> @sprintf(\"%.1f\", y),\n",
    "        grid=true, gridlinewidth=0.125, gridstyle=:dot, gridcolor=:grey, gridalpha=0.5)\n",
    "    \n",
    "    display(plot_p1_p2_p3)\n",
    "\n",
    "end    # do_plots()\n",
    "\n",
    "\n",
    "#######################################################################################################\n",
    "#######################################################################################################\n",
    "#######################################################################################################\n",
    "\n",
    "hostname = gethostname()\n",
    "##println(\"The name of the computer is: \", hostname)\n",
    "\n",
    "if hostname == \"QUEENSLAND-BASIN\"\n",
    "    \n",
    "    display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "    initial_path = \"E:\\\\Card Data\\\\\"\n",
    "    \n",
    "else\n",
    "    \n",
    "    display(HTML(\"<style>.jp-Cell { width: 120% !important; }</style>\"))    \n",
    "    initial_path = \"F:\\\\Card Data\\\\\"\n",
    "    \n",
    "end\n",
    "\n",
    "X_data = Matrix{Float32}(undef, 0, 0)\n",
    "# Initialize GPS_errors as an empty 3D array\n",
    "GPS_errors = Array{Int16}(undef, 2304, 0) #, 1)\n",
    "        \n",
    "infil = pick_file(initial_path)\n",
    "\n",
    "REC_LENGTH = 2304       # Number of WSE's in a Mk4 30-minute record\n",
    "SAMPLE_FREQUENCY = 1.28 # Mk4 sample frequency in Hertz\n",
    "SAMPLE_LENGTH = 1800    # Record length in seconds\n",
    "SAMPLE_RATE = Float64(1 / SAMPLE_FREQUENCY) # Sample spacing in seconds\n",
    "\n",
    "# Initialize output containers\n",
    "X_date = DateTime[]  # Vector to store timestamps for the selected file\n",
    "num_samples = 2304   # Fixed number of samples per record\n",
    "X_data = Float32[]   # Placeholder for water surface elevation data (Heave, North, West)\n",
    "\n",
    "@time begin\n",
    "    println(\"Reading BINARY data from \", infil)\n",
    "    flush(stdout)\n",
    "    \n",
    "    data_array = reinterpret(UInt8, read(infil))\n",
    "\n",
    "    ii = 1\n",
    "    num_records = 0  # Start counting records\n",
    "    while ii < length(data_array)\n",
    "        # Extract message header\n",
    "        message_length = (UInt16(data_array[ii + 2]) << 8) | UInt16(data_array[ii + 3])\n",
    "\n",
    "        # Extract timestamp\n",
    "        yr = (UInt16(data_array[ii + 5]) << 8) | UInt16(data_array[ii + 6])\n",
    "        month = data_array[ii + 7]\n",
    "        day = data_array[ii + 8]\n",
    "        hour = data_array[ii + 9]\n",
    "        minute = data_array[ii + 10]\n",
    "\n",
    "        # Store timestamp for the record\n",
    "        push!(X_date, DateTime(yr, month, day, hour, minute))\n",
    "\n",
    "        # Validate sample frequency\n",
    "        sample_rate_hex = UInt32(data_array[ii + 11]) << 24 | UInt32(data_array[ii + 12]) << 16 | \n",
    "                          UInt32(data_array[ii + 13]) << 8 | UInt32(data_array[ii + 14])\n",
    "        sample_frequency = reinterpret(Float32, sample_rate_hex)\n",
    "\n",
    "        if sample_frequency != 1.28f0\n",
    "            error(\"Error: Sample rate not 1.28 Hz - Program terminated!\")\n",
    "        end\n",
    "\n",
    "        rows = (message_length - 10) ÷ 6  # Calculate number of rows (samples)\n",
    "        if rows != num_samples\n",
    "            error(\"Error: Number of rows per record does not match expected sample count!\")\n",
    "        end\n",
    "\n",
    "        # Allocate temporary vectors for current record\n",
    "        heave_values = Vector{Float32}(undef, rows)\n",
    "        north_values = Vector{Float32}(undef, rows)\n",
    "        west_values = Vector{Float32}(undef, rows)\n",
    "        gps_error = Vector{Int16}(undef, rows)  # Temporary GPS error vector for the current record\n",
    "\n",
    "        for jj ∈ 1:rows\n",
    "            base_idx = ii + 15 + (jj - 1) * 6\n",
    "\n",
    "            # Parse HEX and calculate displacements\n",
    "            heave_values[jj] = reinterpret(Int16, UInt16(parse_hex(data_array, base_idx))) / 100\n",
    "            north_hex = parse_hex(data_array, base_idx + 2)\n",
    "            north_values[jj] = reinterpret(Int16, UInt16(north_hex)) / 100\n",
    "            west_values[jj] = reinterpret(Int16, UInt16(parse_hex(data_array, base_idx + 4))) / 100\n",
    "\n",
    "            # Determine GPS error from the least significant bit of the North value\n",
    "            gps_error[jj] = parse(Int, last(string(north_hex, base=2, pad=16), 1))  # LSB: 1 (error) or 0 (no error)\n",
    "        end\n",
    "\n",
    "        # Append the GPS error for the current record\n",
    "##        GPS_errors = cat(GPS_errors, reshape(gps_error, rows, 1, 1), dims=2)\n",
    "        GPS_errors = hcat(GPS_errors, gps_error)\n",
    "        \n",
    "        # Incrementally add record data to X_data\n",
    "        if isempty(X_data)\n",
    "            X_data = zeros(Float32, rows, 1, 3)  # Initialize with the first record\n",
    "        else\n",
    "            X_data = cat(X_data, reshape([heave_values north_values west_values], rows, 1, 3), dims=2)\n",
    "        end\n",
    "\n",
    "        # Update counters\n",
    "        num_records += 1\n",
    "        ii += message_length + 6\n",
    "    end\n",
    "\n",
    "    println(\"File processing complete: \", num_records, \" records processed.\")\n",
    "end\n",
    "\n",
    "# Locate GPS errors flagged by Datawell\n",
    "column_sums = sum(GPS_errors[:, :, 1], dims=1)  # Sum along the rows (dimension 1)\n",
    "\n",
    "column_sums_vector = vec(column_sums)  # Converts the 1×288 matrix to a 288-element vector\n",
    "records_with_errors = findall(x -> x > 0, column_sums_vector)\n",
    "\n",
    "println(\"\\n\",string(length(records_with_errors)),\" records with GPS errors: \")\n",
    "\n",
    "if isempty(records_with_errors)   \n",
    "    println(\"\\nNo GPS errors flagged by Datawell in \",infil)\n",
    "else\n",
    "    foreach(ii -> println(\"    \", Dates.format(X_date[ii], \"yyyy-mm-dd HH:MM\")), records_with_errors)\n",
    "    foreach(ii -> do_plots(ii, X_date, X_data, GPS_errors), records_with_errors)\n",
    "end    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5254b703-de9f-456f-85ee-66e9d34ba9ef",
   "metadata": {},
   "source": [
    "### Display spectra for records with GPS errors as flagged by Datawell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd8d55-fbb7-4f4b-9869-8163fd43777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate f2 and Pden2 using Welch's method\n",
    "function calculate_spectra(heave_row, sample_frequency)\n",
    "#######################################################\n",
    "    ps_w = welch_pgram(heave_row, 256, 128; onesided=true, nfft=256, fs=sample_frequency, window=hanning)\n",
    "    f2 = freq(ps_w)\n",
    "    Pden2 = power(ps_w)\n",
    "    return f2, Pden2\n",
    "end    # calculate_spectra()\n",
    "\n",
    "\n",
    "# Plot the spectra\n",
    "function plot_spectra(f2, Pden2, X_date)\n",
    "########################################\n",
    "    \n",
    "    title = Dates.format(X_date, \"yyyy-mm-dd HH:MM\")\n",
    "\n",
    "    p1 = plot(f2, Pden2, title=title, fillrange=:0, label=\"\", xlims=(0,0.64), ylims=(0,Inf), size=(1000,600), framestyle=:box)\n",
    "\n",
    "    display(p1)\n",
    "\n",
    "end    # plot_spectra()\n",
    "\n",
    "\n",
    "# Perform spectral calculations\n",
    "sample_frequency = 1.28f0\n",
    "num_records = 144  # Adjust as needed\n",
    "nfft = 256         # FFT size used in Welch's method\n",
    "n_bins = nfft ÷ 2 + 1  # Number of frequency bins (for onesided FFT)\n",
    "\n",
    "# Initialize 2D matrices\n",
    "f2_list = zeros(Float32, num_records, n_bins)\n",
    "Pden2_list = zeros(Float32, num_records, n_bins)\n",
    "\n",
    "for file_idx ∈ 1:num_records\n",
    "    heave_row = X_data[:, file_idx, 1]\n",
    "    f2, Pden2 = calculate_spectra(heave_row, sample_frequency)\n",
    "    f2_list[file_idx, :] = f2\n",
    "    Pden2_list[file_idx, :] = Pden2\n",
    "end\n",
    "\n",
    "if isempty(records_with_errors)   \n",
    "    println(\"\\nNo GPS errors flagged by Datawell in \",infil)\n",
    "else\n",
    "    foreach(ii -> println(\"    \", Dates.format(X_date[ii], \"yyyy-mm-dd HH:MM\")), records_with_errors)\n",
    "    foreach(ii -> plot_spectra(f2, Pden2_list[ii, :], X_date[ii]), records_with_errors)\n",
    "end  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b5007-f8eb-4c9f-ab9e-3a8c8839f1af",
   "metadata": {},
   "source": [
    "### Display spectrogram for selected .RDT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598992a4-f63f-48c7-b54f-77b02e808454",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Spectral calculations complete - now plotting spectrogram!\")\n",
    "\n",
    "using Plots: contourf, cgrad\n",
    "x = X_date\n",
    "y = f2_list[1,:]\n",
    "z = Pden2_list'\n",
    "\n",
    "contourf(x, y, z, size=(1200,600))\n",
    "\n",
    "# display plots to screen\n",
    "tm_tick = range(X_date[1],X_date[end],step=Hour(1))\n",
    "ticks = Dates.format.(tm_tick,\"dd HH:MM\")\n",
    "\n",
    "p1 = contourf(x, y, z, lw=0.25, c=cgrad(:Spectral, rev=true), clims=(0.0,maximum(z)), levels=10, fill=true)\n",
    "\n",
    "# draw grid lines on plot\n",
    "for i in 0:0.1:0.6\n",
    "    hline!(p1, [i], lw=0.5, c=:white, label=\"\")\n",
    "end\n",
    "\n",
    "for i in X_date[1]:Hour(1):X_date[end]\n",
    "    vline!(p1, [i], lw=0.5, c=:white, label=\"\")\n",
    "end\n",
    "\n",
    "foreach(ii -> vline!([X_date[ii]], lw=1, ls=:dash, c=:yellow, label=\"\"), records_with_errors)\n",
    "\n",
    "title=Dates.format(X_date[1], \"yyyy-mm-dd HH:MM\")*\" to \"*Dates.format(X_date[end], \"yyyy-mm-dd HH:MM\")\n",
    "p1_plot = plot(p1, xlabel=\"Date\", xlim=(X_date[1],X_date[end]), xticks=(tm_tick,ticks), xtickfontsize=7, xrotation=90,\n",
    "        ylabel=\"Frequency (Hz)\", ylim=(0,0.4), ytickfontsize=8, \n",
    "        title=title, framestyle = :box,\n",
    "        leftmargin = 15Plots.mm, bottommargin = 15Plots.mm, grid=true, size=(1800,800), gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, colorbar=true)\n",
    "\n",
    "display(p1_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e097e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function calc_and_plot_bounds(xvals, heave, lc, hspan_color, label, errors)\n",
    "###################################################################\n",
    "\n",
    "    Q1 = quantile(heave, 0.25)\n",
    "    Q3 = quantile(heave, 0.75)\n",
    "\n",
    "    multiplier = 1.5\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "\n",
    "    # Calculate dynamic confidence interval\n",
    "    confidence_interval = 3.29 # threshold at the 99.9th percentile level\n",
    "\n",
    "    # Identify z_scores using modified z-score\n",
    "    z_score_indices, mod_z_scores = modified_z_score(heave, confidence_interval)\n",
    "\n",
    "    # Plot confidence limits\n",
    "    confidence_limits = calc_confidence_limits(heave, confidence_interval)\n",
    "\n",
    "    tm_tick = range(xvals[1], xvals[end], step=Minute(1))\n",
    "    ticks = Dates.format.(tm_tick, \"MM\")\n",
    "\n",
    "\n",
    "    px = plot(xvals, heave, xlims=(xvals[1], xvals[end]), lw=0.5, lc=lc, alpha=0.5, \n",
    "        xticks=(tm_tick, ticks), label=label, legendfontsize=12)\n",
    "\n",
    "    px = vline!(xvals[errors], label=\"\", lc=:red, ls=:dot)\n",
    "\n",
    "    if !isempty(z_score_indices)\n",
    "        scatter!(px, xvals[z_score_indices], heave[z_score_indices], \n",
    "            markersize=4, markerstrokecolor=:red, markerstrokewidth=1, \n",
    "            markercolor=:white, markershape=:circle, label=\"Modified Z-score beyond 99.9% confidence limits\")\n",
    "    end\n",
    "\n",
    "    px = hspan!([lower_bound, upper_bound], fillcolor=hspan_color, fillalpha=:0.125, label=\"IQR limits\")\n",
    "    px = hline!([confidence_limits[1], confidence_limits[2]], color=:red, lw=0.5, linestyle=:dash, label=\"99.9% confidence limits\")            \n",
    "    \n",
    "    return(px)\n",
    "\n",
    "end    # calc_and_plot_bounds()\n",
    "\n",
    "\n",
    "function do_heave_north_west_plots(ii, start_time, X_data, GPS_errors)\n",
    "##########################################################\n",
    "\n",
    "    heave = X_data[:, ii, 1]\n",
    "    north = X_data[:, ii, 2]\n",
    "    west = X_data[:, ii, 3]\n",
    "\n",
    "    errors = findall(x -> x == 1, GPS_errors[:, ii, 1])\n",
    "    \n",
    "    end_time = start_time + Minute(30)\n",
    "    xvals = start_time + Microsecond.((0:REC_LENGTH-1) / SAMPLE_FREQUENCY * 1000000)\n",
    "   \n",
    "    tm_tick = range(start_time, end_time, step=Minute(1))\n",
    "    ticks = Dates.format.(tm_tick, \"MM\")\n",
    "            \n",
    "    p1 = calc_and_plot_bounds(xvals, heave, :blue, :lightblue, \"Heave\", errors)\n",
    "\n",
    "    p2 = calc_and_plot_bounds(xvals, north, :red, :pink, \"North\", errors)\n",
    "\n",
    "    p3 = calc_and_plot_bounds(xvals, west, :green, :lightgreen, \"West\", errors)\n",
    "\n",
    "    # Annotate plot with the number of outliers and confidence interval\n",
    "##    num_outliers = length(z_score_indices)\n",
    "##    suspect_string = string(\"  \", string(ii),\" \",Dates.format(start_time, \"yyyy-mm-dd HH:MM\"), \" - \", num_outliers, \" Possible outliers\") # using Confidence Interval of \", \n",
    "##        @sprintf(\"%.2f\", confidence_interval))\n",
    "##    annotate!(p1, xvals[1], maximum(heave) * 0.9, text(suspect_string, :left, 10, :blue))\n",
    "\n",
    "    date_string = Dates.format(start_time, \"yyyy-mm-dd HH:MM\") * \" \" * string(length(errors)) * \" GPS errors\"\n",
    " \n",
    "    plot_displacements = plot(p1, p2, p3, size=(2000, 1000), layout=(3,1), dpi=100, framestyle=:box, fg_legend=:transparent, bg_legend=:transparent, \n",
    "    legend=:topright, xtickfont=font(8), ytickfont=font(8), bottommargin=5Plots.mm, suptitle=date_string,\n",
    "    grid=true, gridlinewidth=0.125, gridstyle=:dot, gridcolor=:grey, gridalpha=0.5)\n",
    " \n",
    "    display(plot_displacements)\n",
    "    \n",
    "end    # do_heave_north_west_plots()  \n",
    "\n",
    "for ii ∈ records_with_errors\n",
    "\n",
    "    # Initialize variables\n",
    "    start_time = X_date[ii]\n",
    "       \n",
    "    do_heave_north_west_plots(ii, start_time, X_data, GPS_errors)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc9f67b-a526-4745-baee-b12fd8e4620b",
   "metadata": {},
   "source": [
    "### Initial declaration of training data matricies"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94b42051-5d96-4a6e-a889-3ea960f30bc8",
   "metadata": {},
   "source": [
    "# Initialize empty 2D matrices with 2304 rows and 0 columns\n",
    "training_data_good = zeros(Float32, 2304, 0)\n",
    "training_data_bad = zeros(Float32, 2304, 0)\n",
    "\n",
    "# Check the results\n",
    "println(size(training_data_good))  # Should print (2304, 20)\n",
    "println(size(training_data_bad))  # Should print (2304, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e188ff9e-dbb8-4305-9686-dad7b28f6e8a",
   "metadata": {},
   "source": [
    "### Build training data matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74224b-2585-4f84-b74b-1a8e99b34b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_with_errors = records_with_errors[2:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e452376-e4df-4e5a-9a44-9dbe558e2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix of records with GPS errors in them\n",
    "new_training_data_bad = X_data[:,records_with_errors,1]\n",
    "println(string(length(records_with_errors)),\" records stored to training_data_bad matrix\")\n",
    "\n",
    "# Find indices of good records (not in records_with_errors)\n",
    "all_records = 1:size(X_data, 2)  # All column indices of X_data\n",
    "records_without_errors = setdiff(all_records, records_with_errors)\n",
    "\n",
    "# Create training_data_good\n",
    "new_training_data_good = X_data[:, records_without_errors, 1];\n",
    "println(string(length(records_without_errors)),\" records stored to training_data_good matrix\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f7fde-929d-4a92-8242-10dcb1c6ba44",
   "metadata": {},
   "source": [
    "### Add new training data to existing matricies and save to .JLD2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd5dd7-1708-45ef-8042-886bb5e37234",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2, Dates\n",
    "\n",
    "##training_data_good = hcat(training_data_good, new_training_data_good)\n",
    "training_data_bad = hcat(training_data_bad, new_training_data_bad)\n",
    "\n",
    "println(\"Good data now \",string(size(training_data_good)[2]),\" records\")\n",
    "println(\"Bad  data now \",string(size(training_data_bad)[2]),\" records\\n\")\n",
    "\n",
    "outfil = \".\\\\Training_data\\\\Mk3_training_data_updated_\" * Dates.format(now(), \"yyyy_mm_dd_HHMM\") * \".JLD2\" \n",
    "\n",
    "# Save the updated good and bad training data\n",
    "@save outfil training_data_good training_data_bad\n",
    "\n",
    "println(\"Updated training data saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487829b3",
   "metadata": {},
   "source": [
    "# *******************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851b6edd-0a23-4c79-96c2-049e081fb686",
   "metadata": {},
   "source": [
    "### Recover earlier separated training data from file (Note: does not include Model data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497d8d3-af9f-4640-9241-21a8a1e166b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2\n",
    "\n",
    "using NativeFileDialog\n",
    "using FilePathsBase\n",
    "\n",
    "# Load the model and optimizer states from the JLD2 file\n",
    "current_path = pwd() * \"\\\\Training_data\"\n",
    "filterlist = \"JLD2\"\n",
    "infil = pick_file(current_path; filterlist)\n",
    "\n",
    "# Load all saved training data\n",
    "@load infil training_data_good training_data_bad training_data_bad\n",
    "\n",
    "println(\"Data and labels loaded successfully.\")\n",
    "println(\"Good data contains \",string(size(training_data_good)[2]),\" records\")\n",
    "println(\"Bad  data contains \",string(size(training_data_bad)[2]),\" records\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4449a423-e9a5-4b58-ba9c-6052338e993a",
   "metadata": {},
   "source": [
    "### Build the Model using a hybrid approach¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd4c43-0d8c-4489-982f-517497e6de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==\n",
    "Calls:\n",
    "\n",
    "    min_max_normalize_matrix()\n",
    "\n",
    "==#\n",
    "\n",
    "# Define autoencoder model\n",
    "hybrid_model = Chain(\n",
    "    Dense(2304, 256, relu),\n",
    "    Dense(256, 128, relu),\n",
    "    Dense(128, 32, relu),\n",
    "    Dense(32, 128, relu),\n",
    "    Dense(128, 256, relu),\n",
    "    Dense(256, 2304)\n",
    ")\n",
    "\n",
    "# Concatenate and normalize the training data\n",
    "training_data_combined = hcat(training_data_good, training_data_bad)\n",
    "training_data_normalized = min_max_normalize_matrix(training_data_combined)\n",
    "training_data_float32 = Float32.(training_data_normalized)\n",
    "\n",
    "hostname = gethostname()\n",
    "println(\"The name of the computer is: \", hostname)\n",
    "\n",
    "# computer-specific actions\n",
    "if hostname == \"QUEENSLAND-BASIN\"  \n",
    "    initial_path = \"E:\\\\Card Data\\\\\"\n",
    "    display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")     \n",
    "    println(\"Building hybrid model now - on this computer it takes about 30s\\n\")\n",
    "else   \n",
    "    initial_path = \"F:\\\\Card Data\\\\\"\n",
    "    display(HTML(\"<style>.jp-Cell { width: 120% !important; }</style>\"))\n",
    "    println(\"Building hybrid model now - on this computer it takes about 200s\\n\")\n",
    "end    \n",
    "flush(stdout)  \n",
    "    \n",
    "@time begin\n",
    "    \n",
    "    # Train the model\n",
    "    loss(x) = Flux.mse(hybrid_model(x), x)\n",
    "    opt = Adam()\n",
    "    \n",
    "    data = Iterators.repeated((training_data_float32,), 100)\n",
    "    Flux.train!(loss, Flux.params(hybrid_model), data, opt)\n",
    "    println(\"Model training complete.\")\n",
    "\n",
    "end\n",
    "\n",
    "println(\"\\nNow select a .RDT file to check for outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec265806-910f-4fbb-92f6-72c196652bf0",
   "metadata": {},
   "source": [
    "### Select a .RDT file to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc40b9f-dab3-4d3d-a664-790db6b86adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert data without creating temporary strings\n",
    "function parse_hex(data_array, idx)\n",
    "###################################\n",
    "    \n",
    "    UInt16(data_array[idx]) << 8 | UInt16(data_array[idx+1])\n",
    "    \n",
    "end    # parse_hex()\n",
    "\n",
    "\n",
    "# Function to check if the LSB is 1 (GPS interference)\n",
    "function check_gps_flag(north_row)\n",
    "##################################\n",
    "    \n",
    "    gps_flag_row = [((n & 0x1) == 1) ? 1 : 0 for n in north_row]\n",
    "    \n",
    "    return(gps_flag_row)\n",
    "    \n",
    "end    # check_gps_flag()\n",
    "\n",
    "\n",
    "hostname = gethostname()\n",
    "##println(\"The name of the computer is: \", hostname)\n",
    "\n",
    "if hostname == \"QUEENSLAND-BASIN\"\n",
    "    \n",
    "    display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "    initial_path = \"E:\\\\Card Data\\\\\"\n",
    "    \n",
    "else\n",
    "    \n",
    "    display(HTML(\"<style>.jp-Cell { width: 120% !important; }</style>\"))    \n",
    "    initial_path = \"F:\\\\Card Data\\\\\"\n",
    "    \n",
    "end\n",
    "\n",
    "X_data = Matrix{Float32}(undef, 0, 0)\n",
    "# Initialize GPS_errors as an empty 3D array\n",
    "GPS_errors = Array{Int16}(undef, 2304, 0) #, 1)\n",
    "        \n",
    "infil = pick_file(initial_path)\n",
    "\n",
    "REC_LENGTH = 2304       # Number of WSE's in a Mk4 30-minute record\n",
    "SAMPLE_FREQUENCY = 1.28 # Mk4 sample frequency in Hertz\n",
    "SAMPLE_LENGTH = 1800    # Record length in seconds\n",
    "SAMPLE_RATE = Float64(1 / SAMPLE_FREQUENCY) # Sample spacing in seconds\n",
    "\n",
    "# Initialize output containers\n",
    "X_date = DateTime[]  # Vector to store timestamps for the selected file\n",
    "num_samples = 2304   # Fixed number of samples per record\n",
    "X_data = Float32[]   # Placeholder for water surface elevation data (Heave, North, West)\n",
    "\n",
    "@time begin\n",
    "    println(\"Reading BINARY data from \", infil)\n",
    "    flush(stdout)\n",
    "    \n",
    "    data_array = reinterpret(UInt8, read(infil))\n",
    "\n",
    "    ii = 1\n",
    "    num_records = 0  # Start counting records\n",
    "    while ii < length(data_array)\n",
    "        # Extract message header\n",
    "        message_length = (UInt16(data_array[ii + 2]) << 8) | UInt16(data_array[ii + 3])\n",
    "\n",
    "        # Extract timestamp\n",
    "        yr = (UInt16(data_array[ii + 5]) << 8) | UInt16(data_array[ii + 6])\n",
    "        month = data_array[ii + 7]\n",
    "        day = data_array[ii + 8]\n",
    "        hour = data_array[ii + 9]\n",
    "        minute = data_array[ii + 10]\n",
    "\n",
    "        # Store timestamp for the record\n",
    "        push!(X_date, DateTime(yr, month, day, hour, minute))\n",
    "\n",
    "        # Validate sample frequency\n",
    "        sample_rate_hex = UInt32(data_array[ii + 11]) << 24 | UInt32(data_array[ii + 12]) << 16 | \n",
    "                          UInt32(data_array[ii + 13]) << 8 | UInt32(data_array[ii + 14])\n",
    "        sample_frequency = reinterpret(Float32, sample_rate_hex)\n",
    "\n",
    "        if sample_frequency != 1.28f0\n",
    "            error(\"Error: Sample rate not 1.28 Hz - Program terminated!\")\n",
    "        end\n",
    "\n",
    "        rows = (message_length - 10) ÷ 6  # Calculate number of rows (samples)\n",
    "        if rows != num_samples\n",
    "            error(\"Error: Number of rows per record does not match expected sample count!\")\n",
    "        end\n",
    "\n",
    "        # Allocate temporary vectors for current record\n",
    "        heave_values = Vector{Float32}(undef, rows)\n",
    "        north_values = Vector{Float32}(undef, rows)\n",
    "        west_values = Vector{Float32}(undef, rows)\n",
    "        gps_error = Vector{Int16}(undef, rows)  # Temporary GPS error vector for the current record\n",
    "\n",
    "        for jj ∈ 1:rows\n",
    "            base_idx = ii + 15 + (jj - 1) * 6\n",
    "\n",
    "            # Parse HEX and calculate displacements\n",
    "            heave_values[jj] = reinterpret(Int16, UInt16(parse_hex(data_array, base_idx))) / 100\n",
    "            north_hex = parse_hex(data_array, base_idx + 2)\n",
    "            north_values[jj] = reinterpret(Int16, UInt16(north_hex)) / 100\n",
    "            west_values[jj] = reinterpret(Int16, UInt16(parse_hex(data_array, base_idx + 4))) / 100\n",
    "\n",
    "            # Determine GPS error from the least significant bit of the North value\n",
    "            gps_error[jj] = parse(Int, last(string(north_hex, base=2, pad=16), 1))  # LSB: 1 (error) or 0 (no error)\n",
    "        end\n",
    "\n",
    "        # Append the GPS error for the current record\n",
    "##        GPS_errors = cat(GPS_errors, reshape(gps_error, rows, 1, 1), dims=2)\n",
    "        GPS_errors = hcat(GPS_errors, gps_error)\n",
    "        \n",
    "        # Incrementally add record data to X_data\n",
    "        if isempty(X_data)\n",
    "            X_data = zeros(Float32, rows, 1, 3)  # Initialize with the first record\n",
    "        else\n",
    "            X_data = cat(X_data, reshape([heave_values north_values west_values], rows, 1, 3), dims=2)\n",
    "        end\n",
    "\n",
    "        # Update counters\n",
    "        num_records += 1\n",
    "        ii += message_length + 6\n",
    "    end\n",
    "\n",
    "    println(\"File processing complete: \", num_records, \" records processed.\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7bd1b9-34ab-4400-a1ff-9aee0be7800f",
   "metadata": {},
   "source": [
    "### Run the hybrid model against data in the selected .BVA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae206bf-0d63-4b90-99d4-67040fb78062",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#==\n",
    "Calls:\n",
    "\n",
    "    detect_outliers()\n",
    "\n",
    "==#\n",
    "\n",
    "@time begin\n",
    "    \n",
    "    # identify possible outliers in Heave, North, and West data\n",
    "    outlier_heave, uncertain_heave, outlier_dates_heave, uncertain_dates_heave, good_thresh_heave, bad_thresh_heave = \n",
    "        detect_outliers(X_data[:,:,1], X_date, training_data_good, training_data_bad, hybrid_model)\n",
    "    outlier_north, uncertain_north, outlier_dates_north, uncertain_dates_north, good_thresh_north, bad_thresh_north = \n",
    "        detect_outliers(X_data[:,:,2], X_date, training_data_good, training_data_bad, hybrid_model)\n",
    "    outlier_west, uncertain_west, outlier_dates_west, uncertain_dates_west, good_thresh_west, bad_thresh_west = \n",
    "        detect_outliers(X_data[:,:,3], X_date, training_data_good, training_data_bad, hybrid_model)\n",
    "    \n",
    "    # Combine and deduplicate dates across components\n",
    "    all_outlier = unique(vcat(outlier_heave, outlier_north, outlier_west))\n",
    "    all_uncertain = unique(vcat(uncertain_heave, uncertain_north, uncertain_west))\n",
    "    \n",
    "    # Combine and deduplicate dates across components\n",
    "    all_outlier_dates = unique(vcat(outlier_dates_heave, outlier_dates_north, outlier_dates_west))\n",
    "    all_uncertain_dates = unique(vcat(uncertain_dates_heave, uncertain_dates_north, uncertain_dates_west));\n",
    "\n",
    "end\n",
    "\n",
    "# Output results\n",
    "println(\"\\nFor \",infil,\"\\n\")\n",
    "if !isempty(all_outlier_dates)\n",
    "    println(string(length(all_outlier_dates)), \" records contain suspected outliers at the following dates:\\n\")\n",
    "    for date in all_outlier_dates\n",
    "        println(\"    \", Dates.format(date, \"yyyy-mm-dd HH:MM\"))\n",
    "    end\n",
    "    print(\"\\n\")\n",
    "else\n",
    "    println(\"No suspected outliers detected.\\n\")\n",
    "end\n",
    "\n",
    "if !isempty(all_uncertain_dates)\n",
    "    println(string(length(all_uncertain_dates)), \" records contain uncertain data points at the following dates:\\n\")\n",
    "    for date in all_uncertain_dates\n",
    "        println(\"    \", Dates.format(date, \"yyyy-mm-dd HH:MM\"))\n",
    "    end\n",
    "else\n",
    "    println(\"No uncertain data points detected.\")\n",
    "end\n",
    "\n",
    "println(\"\\nNow run the plot routine to view the suspect records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8a39e-d215-4046-b6c9-6a189a9bf8c9",
   "metadata": {},
   "source": [
    "### Plot records with suspect data (as identified by the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca8eb1-4b13-450b-ba45-c4da911dfffc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#==\n",
    "Calls:\n",
    "\n",
    "    do_heave_north_west_plots()\n",
    "\n",
    "==#\n",
    "\n",
    "jj = 1\n",
    "\n",
    "for ii ∈ all_outlier\n",
    "\n",
    "    # Initialize variables\n",
    "#    start_time = X_date[ii]\n",
    "    \n",
    "##    kk = all_outlier[ii]\n",
    "\n",
    "    # Initialize variables\n",
    "    start_time = X_date[ii]\n",
    "       \n",
    "    do_heave_north_west_plots(ii, start_time, X_data, jj)\n",
    "\n",
    "    jj += 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3fa533",
   "metadata": {},
   "source": [
    "### Select new bad-data to be added to training_data_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f6ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_data_bad = zeros(Float32, 2304, 0)\n",
    "\n",
    "# Enter indicies of bad data from plots\n",
    "bad_data_indices = [3] # <----- Change these values!\n",
    "\n",
    "for ii in bad_data_indices\n",
    "    \n",
    "    kk = all_outlier[ii]\n",
    "    \n",
    "    new_column = reshape(X_data[:, kk, 1], :, 1)  # Ensure it’s a column vector\n",
    "    new_training_data_bad = hcat(new_training_data_bad, new_column)\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0344cb",
   "metadata": {},
   "source": [
    "### Update the training_data_bad and create an updated training data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f92078",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2, Dates\n",
    "\n",
    "##training_data_good = hcat(training_data_good, new_training_data_good)\n",
    "training_data_bad = hcat(training_data_bad, new_training_data_bad)\n",
    "\n",
    "println(\"Good data now \",string(size(training_data_good)[2]),\" records\")\n",
    "println(\"Bad  data now \",string(size(training_data_bad)[2]),\" records\\n\")\n",
    "\n",
    "outfil = \".\\\\Training_data\\\\Mk3_training_data_updated_\" * Dates.format(now(), \"yyyy_mm_dd_HHMM\") * \".JLD2\" \n",
    "\n",
    "# Save the updated good and bad training data\n",
    "@save outfil training_data_good training_data_bad\n",
    "\n",
    "println(\"Updated bad training data saved successfully.\")\n",
    "println(\"NOTE: you will need to download the new training data file and build the model again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74e059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for ii in bad_data_indices\n",
    "    \n",
    "    kk = all_outlier[ii]\n",
    "    \n",
    "    start_time = X_date[kk]\n",
    "    p1 = plot!(X_data[:,kk,1], lc=:blue, alpha=:0.5, label=string(\"Heave\"))\n",
    "    end_time = start_time + Minute(30)\n",
    "    xvals = start_time + Microsecond.((0:REC_LENGTH-1) / SAMPLE_FREQUENCY * 1000000)\n",
    "\n",
    "    p1 = plot(size=(2500,300), framestyle=:box, fg_legend=:transparent, bg_legend=:transparent, )\n",
    "    errors = findall(x -> x == 1, GPS_errors[:, all_outlier[ii], 1])\n",
    "    \n",
    "    p1 = vline!([errors], lc=:red, alpha=:0.5, label=\"\")\n",
    "    \n",
    "    p1 = plot!(X_data[:,kk,1], lc=:blue, alpha=:0.5, label=string(X_date[kk]))\n",
    "    \n",
    "    display(p1)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beacedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfil = \".\\\\Training_data\\\\Mk3_training_data_updated_\" * Dates.format(now(), \"yyyy_mm_dd_HHMM\") * \".JLD2\" \n",
    "\n",
    "# Save the updated good and bad training data\n",
    "@save outfil training_data_good training_data_bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab6632",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Glob: glob\n",
    "using NativeFileDialog: pick_folder\n",
    "using Dates\n",
    "using Tk\n",
    "\n",
    "function unzip(pairs::Vector{<:Tuple})\n",
    "######################################    \n",
    "    \n",
    "    firsts = [p[1] for p in pairs]\n",
    "    seconds = [p[2] for p in pairs]\n",
    "    thirds = [p[3] for p in pairs]\n",
    "    \n",
    "    return(firsts, seconds, thirds)\n",
    "\n",
    "end    # unzip()\n",
    "\n",
    "\n",
    "function decode_rdt_files(rdt_files)\n",
    "####################################\n",
    "    \n",
    "    dates = Date[]\n",
    "    Hmax_values = Float64[]\n",
    "\n",
    "    for file in rdt_files\n",
    "        # Extract the filename (last part)\n",
    "        filename = split(file, '\\\\') |> last\n",
    "        \n",
    "        # Decode max{Hs}\n",
    "        Hs_label = filename[6:8]\n",
    "        max_Hs = (Hs_label[1] - 'A') * 676 + (Hs_label[2] - 'A') * 26 + (Hs_label[3] - 'A')\n",
    "        push!(Hmax_values, max_Hs / 100.0)  # Convert cm to meters\n",
    "        \n",
    "        # Decode date\n",
    "        day = parse(Int, filename[1:2])\n",
    "        month = parse(Int, filename[3:4])\n",
    "        year_part = parse(Int, filename[5])\n",
    "\n",
    "        # Adjust the year based on decade logic\n",
    "        year = if year_part == 9\n",
    "            2010 + year_part\n",
    "        elseif year_part == 0\n",
    "            2020\n",
    "        elseif year_part == 1\n",
    "            2021\n",
    "        else\n",
    "            error(\"Unexpected year part in filename: $filename\")\n",
    "        end\n",
    "\n",
    "        push!(dates, Date(year, month, day))\n",
    "    end\n",
    "\n",
    "    # Return dates and Hmax_values as a tuple\n",
    "    return(dates, Hmax_values)\n",
    "        \n",
    "    end    # decode_rdt_files()\n",
    "\n",
    "    \n",
    "\n",
    "# Define the path to the directory you want to search in\n",
    "directory_path = pick_folder()\n",
    "\n",
    "# Use glob to find all .RDT files in the directory and subdirectories\n",
    "rdt_path = glob(\".//*.RDT\", directory_path)\n",
    "rdt_files = rdt_path[1:end-1]  # Remove the file named TMP.RDT\n",
    "\n",
    "rdt_file_names = basename.(rdt_files)\n",
    "    \n",
    "\n",
    "# Sort the results by date\n",
    "sorted_pairs = sort(collect(zip(dates, Hmax_values, basename.(rdt_files))), by = x -> x[1])\n",
    "\n",
    "# Extract sorted dates, Hmax_values, and rdt_files\n",
    "sorted_dates, sorted_Hmax_values, sorted_rdt_files = unzip(sorted_pairs)\n",
    "\n",
    "#plot the results for checking\n",
    "title = Dates.format(values(sorted_dates)[1], \"yyyy-mm-dd\")* \" to \" * Dates.format(sorted_dates[end], \"yyyy-mm-dd\")\n",
    "plot(sorted_dates,sorted_Hmax_values, size=(1200,600), label=\"Hsig\", title=title, framestyle=:box, fg_legend=:transparent, bg_legend=:transparent, )\n",
    "\n",
    "date_array = Dates.format.(values(sorted_dates), \"yyyy-mm-dd\")\n",
    "    \n",
    "w = Toplevel(\"Select Date\", 235, 600)\n",
    "tcl(\"pack\", \"propagate\", w, false)\n",
    "f = Frame(w)\n",
    "pack(f, expand=true, fill=\"both\")\n",
    "\n",
    "f1 = Frame(f)\n",
    "lb = Treeview(f1, date_array)\n",
    "scrollbars_add(f1, lb)\n",
    "pack(f1,  expand=true, fill=\"both\")\n",
    "\n",
    "tcl(\"ttk::style\", \"configure\", \"TButton\", foreground=\"blue\", font=\"arial 16 bold\")\n",
    "b = Button(f, \"Ok\")\n",
    "pack(b)\n",
    "\n",
    "bind(b, \"command\") do path\n",
    "    \n",
    "    date_choice = get_value(lb);\n",
    "    println(date_choice)\n",
    "    indices = values(findall(x -> x == date_choice, date_array))\n",
    "    \n",
    "    global infil = sorted_rdt_files[indices]\n",
    "\n",
    "end\n",
    "    \n",
    "println(infil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dca5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "findall(x -> x == \"2020-01-15\", date_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "values([\"2020-01-03\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d66f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
